{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering\n",
    "https://www.kaggle.com/andyxie/k-means-clustering-implementation-in-python\n",
    "K-Means Clustering\n",
    "This work is based on Mubaris' great work ( https://mubaris.com/2017/10/01/kmeans-clustering-in-python/).\n",
    "\n",
    "A description of the algorithm can be found: https://github.com/andrewxiechina/DataScience/blob/master/K-Means/cs229-notes7a%202.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from copy import deepcopy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Data\n",
    "Generate random data normally distributed around 3 centers, with a noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set three centers, the model should predict similar results\n",
    "center_1 = np.array([1,1])\n",
    "center_2 = np.array([5,5])\n",
    "center_3 = np.array([8,1])\n",
    "\n",
    "# Generate random data and center it to the three centers\n",
    "data_1 = np.random.randn(200, 2) + center_1\n",
    "data_2 = np.random.randn(200,2) + center_2\n",
    "data_3 = np.random.randn(200,2) + center_3\n",
    "\n",
    "data = np.concatenate((data_1, data_2, data_3), axis = 0)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], s=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 3\n",
    "# Number of training data\n",
    "n = data.shape[0]\n",
    "# Number of features in the data\n",
    "c = data.shape[1]\n",
    "\n",
    "# Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "mean = np.mean(data, axis = 0)\n",
    "std = np.std(data, axis = 0)\n",
    "centers = np.random.randn(k,c)*std + mean\n",
    "\n",
    "# Plot the data and the centers generated as random\n",
    "plt.scatter(data[:,0], data[:,1], s=7)\n",
    "plt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_old = np.zeros(centers.shape) # to store old centers\n",
    "centers_new = deepcopy(centers) # Store new centers\n",
    "\n",
    "data.shape\n",
    "clusters = np.zeros(n)\n",
    "distances = np.zeros((n,k))\n",
    "\n",
    "error = np.linalg.norm(centers_new - centers_old)\n",
    "\n",
    "# When, after an update, the estimate of that center stays the same, exit loop\n",
    "\n",
    "iterations = 0 #for tracking purposes, only.\n",
    "while error != 0:\n",
    "    # Measure the distance to every center\n",
    "    for i in range(k):\n",
    "        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n",
    "    # Assign all training data to closest center\n",
    "    clusters = np.argmin(distances, axis = 1)\n",
    "    \n",
    "    centers_old = deepcopy(centers_new)\n",
    "    # Calculate mean for every cluster and update the center\n",
    "    for i in range(k):\n",
    "        centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "    iterations+=1\n",
    "centers_new\n",
    "iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and the centers generated as random\n",
    "plt.scatter(data[:,0], data[:,1], s=7)\n",
    "plt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test On Iris Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Iris.csv\") #load the dataset\n",
    "df.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical data to number 0-2\n",
    "df[\"Species\"] = pd.Categorical(df[\"Species\"])\n",
    "df[\"Species\"] = df[\"Species\"].cat.codes\n",
    "# Change dataframe to numpy matrix\n",
    "data = df.values[:, 0:4]\n",
    "category = df.values[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 3\n",
    "# Number of training data\n",
    "n = data.shape[0]\n",
    "# Number of features in the data\n",
    "c = data.shape[1]\n",
    "\n",
    "# Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "mean = np.mean(data, axis = 0)\n",
    "std = np.std(data, axis = 0)\n",
    "centers = np.random.randn(k,c)*std + mean\n",
    "\n",
    "# Plot the data and the centers generated as random\n",
    "colors=['orange', 'blue', 'green']\n",
    "for i in range(n):\n",
    "    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\n",
    "plt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_old = np.zeros(centers.shape) # to store old centers\n",
    "centers_new = deepcopy(centers) # Store new centers\n",
    "\n",
    "data.shape\n",
    "clusters = np.zeros(n)\n",
    "distances = np.zeros((n,k))\n",
    "\n",
    "error = np.linalg.norm(centers_new - centers_old)\n",
    "\n",
    "# When, after an update, the estimate of that center stays the same, exit loop\n",
    "while error != 0:\n",
    "    # Measure the distance to every center\n",
    "    for i in range(k):\n",
    "        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n",
    "    # Assign all training data to closest center\n",
    "    clusters = np.argmin(distances, axis = 1)\n",
    "    \n",
    "    centers_old = deepcopy(centers_new)\n",
    "    # Calculate mean for every cluster and update the center\n",
    "    for i in range(k):\n",
    "        centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "centers_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and the centers generated as random\n",
    "colors=['orange', 'blue', 'green']\n",
    "for i in range(n):\n",
    "    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\n",
    "plt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering continued...\n",
    "1. Add dataset for the team to try on.\n",
    "\n",
    "1. How can we visualize multiple dimension data? Create a second part to show this!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
